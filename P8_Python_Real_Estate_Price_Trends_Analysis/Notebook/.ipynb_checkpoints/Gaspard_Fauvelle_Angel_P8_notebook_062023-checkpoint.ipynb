{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenClassrooms - Projet 8 - Analysez l'évolution des prix de l'immobilier avec Python\n",
    "## Abstract :\n",
    "      Client : Les plus beaux logis de Paris ;\n",
    "      Secteur : Gestion immobilière sur Paris intra-murros ;\n",
    "      Segments : Appartements et locaux commerciaux ;\n",
    "      Objectif du client : Vendre une partie des actifs provenant du secteur le moins rentable afin de constituer une réserve de trésorerie.\n",
    "      Notre Objectif :  \n",
    "        Effectuer une analyse exploratoire des données de marché des années passées à partir de l’historique des transactions ;  \n",
    "        Entraîner un modèle de prédiction régressif sur ce même jeu de données ;  \n",
    "        Appliquer le modèle de prédiction sur le portefeuille des logements non valorisés, par segment ;  \n",
    "        Conclure avec une réponse appropriée à l’objectif du client, basée sur les résultats de l’analyse exploratoire et de l’application du modèle.  \n",
    "## Sommaire :\n",
    "    1- Préparations du Notebook\n",
    "      1. Introduction\n",
    "      2. Importations\n",
    "        2.1 Import du script\n",
    "        2.2 Import des données dans un dataframe\n",
    "      3. Amélioration de lecture\n",
    "    2- Pré-processus des jeux de données\n",
    "      1. Nettoyage des données (Data Cleaning)\n",
    "        1.1 Analyse des Lignes/Cellules/Valeurs manquantes\n",
    "        2.2\n",
    "      2. Modification des types de données\n",
    "      3. Modification de la variable temporelle\n",
    "    3- Analyses Statistiques\n",
    "      1. Analyse Descriptive\n",
    "      2. Analyse Exploratoire\n",
    "        1.2. Analyse uni/multivariée\n",
    "      2. Analyse Inférentielle\n",
    "        2.1. Etude des correlations\n",
    "        2.2. Conclusion d'analyse\n",
    "    4- Machine Learning\n",
    "      1. Analyse prédictive Supervisée Régressive\n",
    "        1.1.1. Entraînement des modèles\n",
    "          1.1.1.1. Pré-processus des données\n",
    "          1.1.1.2. Les différents modèles et leurs hyper-paramètres\n",
    "          1.1.1.3. Résultats des modèles\n",
    "          1.1.1.4. Conclusion sur les limites\n",
    "        1.1.2. Prédiction de la variable de la valeur foncière dans le portefeuille\n",
    "      2. Analyse Préscriptive\n",
    "      3. Analyse prédictive Non-supervisée\n",
    "        3.3.1. Pré-processus de l'échantillon\n",
    "        3.3.2. Modèle de clustering\n",
    "        3.3.3. Matrice de corrélation\n",
    "        3.3.4. Conclusion sur les limites\n",
    "## 1- Préparations du Notebook\n",
    "### 1. Introduction :\n",
    "      Cette partie concerne :\n",
    "        L'importation du fichier script.py, contenant :\n",
    "          Librairies importés et Fonctions employées :\n",
    "            Regroupant une série de méthodes provenant de Pandas ;\n",
    "            Créant des jeux de données filtrés ;\n",
    "            Concernant l'emploi, l'erreur, et l'affichage des prédictions et leur résultats ;\n",
    "        L'importation des données excel, que l'on va exploiter via la librairie \"Panda\" nommé \"pd\" ;\n",
    "        L'amélioration de lecture des tableaux de données retournés.\n",
    "### 2. Importations\n",
    "#### 2.1 Import du script :\n",
    "        Contenant les librairies permettant l'analyse, manipulation, calculs et prédictions de données, et de visualisation sur graphique d'une part ;  \n",
    "        Et contenant l'ensemble des fonctions employées à l'avenir d'autre part ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.script import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Import des données dans un dataframe :\n",
    "        Nous allons importer les données dans le notebook via la bibliothèque Panda, nommé \"pd\", et sa méthode \"read_excel\", afin d'exploiter les jeux de données.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo = pd.read_excel('docs/historique_immobilier_paris_2017_2021_vdef2.xlsx')\n",
    "sample = pd.read_excel('docs/echantillon_a_classer.xlsx')\n",
    "sample_soluce = pd.read_excel('docs/echantillon_a_classer_solution.xlsx')\n",
    "wallet = pd.read_excel('docs/portefeuille_actifs.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Amélioration de lecture :\n",
    "        Via l'affichage des colonnes, selon la longueur des valeurs, et de tirets afin d'espacer certaines phrases sans rapport direct :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('compute.use_bottleneck', False)\n",
    "pd.set_option('compute.use_numexpr', False)\n",
    "separe = '-'*75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Pré-processus des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Dans cette première partie, nous allons analyser le jeu de données que nous avons à notre disposition dans sa forme.  \n",
    "        Notre objectif est de repérer, corriger et modifier, les variables, valeurs et types de données.\n",
    "        Grâce à ce travail, nous pourrons traiter sous toute couture, chacune des analyses et prédictions, sans aucune conséquence d'altération.\n",
    "### 1. Nettoyage des données (Data Cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [\n",
    "    (histo, 'Historique', ['date_mutation'], ['type_local', 'code_type_local']),\n",
    "    (wallet, 'Portefeuille', None, None),\n",
    "    (sample, 'Echantillon', ['valeur_fonciere'], None)\n",
    "]\n",
    "\n",
    "for df, name, columns, groupby in dataframes:\n",
    "    get_table_info(df, name)\n",
    "    analyze_dataframe(df, name, columns, groupby)\n",
    "    print(separe)\n",
    "    print(separe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Dans la table historique, se trouve deux catégories, les colonnes code_type_local, et type_local, classant les données en deux groupes distincts :\n",
    "            2, semblant être associé à Appartement, et 4, semblant être associé à Local industriel. commercial ou assimilé.\n",
    "        Par contre, il s'y trouve, 16 lignes dupliquées.\n",
    "        Dans la table portefeuille, se trouve la même colonne code_type_local.\n",
    "#### 1.1 Création de nouveaux jeu de données sans duplications :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [('Historique', histo), ('Portefeuille', wallet)]\n",
    "for name, table in tables:\n",
    "    duplicates = table[table.duplicated(keep=False)].copy()\n",
    "    if name == 'Historique':\n",
    "        # Compter le nombre de lignes dupliquées pour chaque groupe\n",
    "        duplicates['count_even_row'] = duplicates.groupby(duplicates.columns.tolist())['valeur_fonciere'].transform('count')\n",
    "        # Grouper les lignes par valeur_fonciere et surface_reelle, et afficher la première ligne de chaque groupe\n",
    "        display(duplicates.groupby(['valeur_fonciere', 'surface_reelle']).first())\n",
    "        duplicates_mask = table.duplicated(keep='first')\n",
    "        # Créer une nouvelle table sans les lignes dupliquées\n",
    "        histo_clean = table[~duplicates_mask]\n",
    "        histo_clean = histo_clean.reset_index(drop=True)\n",
    "        # Afficher les lignes de la table sans doublons\n",
    "        analyze_dataframe(histo_clean, name, ['date_mutation'], ['type_local', 'code_type_local'])\n",
    "    elif name == 'Portefeuille':\n",
    "        # Marquer les lignes dupliquées\n",
    "        duplicates.loc[:, 'count_even_row'] = True\n",
    "        # Afficher les lignes dupliquées\n",
    "        display(duplicates)\n",
    "        duplicates = duplicates.drop_duplicates(keep='first')\n",
    "        # Supprimer les doublons de la dataframe wallet\n",
    "        wallet_clean = table[~table.index.isin(duplicates.index)]\n",
    "        wallet_clean = wallet_clean.reset_index(drop=True)\n",
    "        analyze_dataframe(wallet_clean, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Le nettoyage étant terminé, nous allons procéder à un pré-traitement des données.\n",
    "        Mais vérifions les dates d'historiques de transactions :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modification des types de données (Transformation des DataTypes)\n",
    "        Affichage des types de données de chaque tables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [('Historique', histo_clean), ('Portefeuille', wallet_clean), ('Échantillon à classer', sample), ('Échantillon soluce', sample_soluce)]\n",
    "for name, table in tables:\n",
    "    display(name)\n",
    "    display(table.info())\n",
    "    print(separe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Dans chacun des jeux de données, beaucoups de types attribués sont trop puissant pour des données aussi imprécises.  \n",
    "        La modification des types de données, permettront un allégement drastique du poids des jeux de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Analyse de la variable qualitative \"Type de bien\", avec la date\n",
    "Regardons les différents types de biens immobiliers, leur clés associées que nous avons dans nos données, et ce, avec l'historique de transactions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correspondance = histo_clean.groupby(['type_local', 'code_type_local']).size().reset_index(name='count').sort_values(by='count', ascending=False)\n",
    "# Calculer le nombre total de transactions\n",
    "total = correspondance['count'].agg('sum')\n",
    "# Ajouter une ligne avec le nombre total de transactions\n",
    "correspondance = pd.concat([correspondance, pd.DataFrame({'type_local': ['total'], 'code_type_local': [''], 'count': [total]})], ignore_index=True)\n",
    "# Obtenir la date minimale et la date maximale de la colonne de dates\n",
    "date_min = histo_clean['date_mutation'].min().strftime('%Y-%m-%d')\n",
    "date_max = histo_clean['date_mutation'].max().strftime('%Y-%m-%d')\n",
    "# Ajouter un titre au-dessus du tableau\n",
    "correspondance = correspondance.style.set_caption(f\"Le nombre de transactions du {date_min} au {date_max}:\")\n",
    "# Afficher le tableau\n",
    "display(correspondance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Changement des Dtypes des trois datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter 'date_mutation' à votre dictionnaire de conversions\n",
    "conversions = {\n",
    "    'code_postal': 'category',\n",
    "    'nom_commune': 'category',\n",
    "    'surface_reelle': 'uint',\n",
    "    'surface_reelle_bati': 'uint',\n",
    "    'surface_carrez': 'float32',\n",
    "    'code_commune': 'category',\n",
    "    'nombre_pieces_principales': 'uint',\n",
    "    'adresse_numero': 'uint',\n",
    "    'adresse_nom_voie': 'category',\n",
    "    'code_type_local': 'category',\n",
    "    'type_local': 'category',\n",
    "    'valeur_fonciere': 'float32',\n",
    "    'longitude': 'float32',\n",
    "    'latitude': 'float32',\n",
    "}\n",
    "\n",
    "dataframes = [\n",
    "    (histo_clean, 'Historique'),\n",
    "    (wallet_clean, 'Portefeuille'),\n",
    "    (sample, 'Échantillon'),\n",
    "    (sample_soluce, \"Solution de l'échantillon\")\n",
    "]\n",
    "# Convertir les colonnes\n",
    "for df, name in dataframes:\n",
    "    convert_columns_inplace(df, conversions)\n",
    "    display(name)\n",
    "    display(df.info())\n",
    "    print(separe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Nous nous retrouvons donc avec des données correspondantes permettant aux jeux de données :  \n",
    "            Un changement de type de données en cohérence avec les valeurs présentes :  \n",
    "        Exemple: les catégories ;\n",
    "            J'ai attribué le type de données \"category\", auprès des colonnes contenant un jeu de valeurs non distincts, permettant de trier les différents profils.\n",
    "            type_local contient deux valeurs, différentes bien qu'elles soient des Strings(chaînes de caractères) à l'origine, elles font office de catégorie ;\n",
    "            De même pour le code_type_local, dont ses valeurs sont des Integers(nombres entiers non relatifs) ;\n",
    "            Ou encore le code_postal, et le nom_commune.  \n",
    "        Avec un allègement du poids, passant donc :\n",
    "            Historique : D'un poids de 1.8+ MBytes à 753.5 kBytes, soit près de 2.5 fois moins lourd ;\n",
    "            Portefeuille : D'un poids de 25.9+ kBytes à 21.7 kBytes ;  \n",
    "            Echantillon : D'un poids de 1.4+ kBytes à 764.0 Bytes, soit quasi 2 fois moins lourd ;\n",
    "            Echantillon_soluce : D'un poids de 2.0+ kBytes à 1.1 kBytes, soit quasi 2 fois moins lourd ;\n",
    "        Nous avons donc économisé sur un total de 1872.5 kB (1872.5 kB), 1.095 MB, soit près de 58.5% du poids de départ via la conversion de données.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modification des données (Data Transform/Normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_m2 = histo_clean.copy()\n",
    "histo_m2['prix_m2'] = (histo_m2.valeur_fonciere / histo_m2.surface_reelle).astype('float32')\n",
    "histo_m2['year_mutation'] = histo_m2.date_mutation.dt.year\n",
    "histo_m2['ordinal_mutation'] = histo_m2.date_mutation.apply(lambda date: np.uint32(date.toordinal()))\n",
    "display(histo_m2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_date = dt.datetime(2022, 12, 31)\n",
    "wallet_clean['year_mutation'] = prediction_date.year\n",
    "wallet_clean['year_mutation'] = wallet_clean['year_mutation'].astype('uint32')\n",
    "wallet_m2 = wallet_clean.rename(columns={\"surface_reelle_bati\": \"surface_reelle\"})\n",
    "wallet_m2['ordinal_mutation'] = wallet_m2.year_mutation.apply(lambda year: dt.datetime(year, 1, 1).toordinal())\n",
    "\n",
    "display(wallet_m2.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pred = sample.copy()\n",
    "sample_pred['prix_m2'] = (sample_pred.valeur_fonciere / sample_pred.surface_reelle).astype('float32')\n",
    "display(sample_pred.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_soluce = sample_soluce.copy()\n",
    "sample_soluce['prix_m2'] = (sample_soluce.valeur_fonciere / sample_soluce.surface_reelle).astype('float32')\n",
    "display(sample_soluce.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Occurrence des jeux de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [('Historique', histo), ('Portefeuille', wallet_clean), ('Échantillon', sample)]\n",
    "for i, (name1, table1) in enumerate(tables):\n",
    "    for name2, table2 in tables[i+1:]:\n",
    "        occur = (table1.columns).intersection(table2.columns)\n",
    "        print(f\"Colonnes {name1} {name2} occurrentes:\")\n",
    "        print(occur)\n",
    "        print(separe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous nous retrouvons donc avec 4 colonnes communes que sont la valeur_foncière, le code_postal, le nom_commune, et la surface_reelle.  \n",
    "Aucune valeur des deux datasets sont nulles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Préparation des jeux de données filtrés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_apartments_and_commercial = request_analyze_graph(histo_m2, 'historique prix au m2', None, None, False)\n",
    "formatted_values = ' et '.join(filtered_apartments_and_commercial.type_local.unique())\n",
    "print(f\"Les types de biens inclus dans ce jeu de données sont de types : {formatted_values}.\")\n",
    "# Voici le dataframe trié pour ne retourner que les appartements :\n",
    "filtered_apartments = request_analyze_graph(histo_m2, 'historique prix au m2', {'type_local': 'Appartement'}, None, False)\n",
    "formatted_values = ', '.join(filtered_apartments.type_local.unique())\n",
    "print(f\"Les types de biens inclus dans ce jeu de données sont de types : {formatted_values}.\")\n",
    "# Voici le dataframe trié pour ne retourner que les locaux commerciaux :\n",
    "filtered_corpo = request_analyze_graph(histo_m2, 'historique prix au m2', {'type_local': 'Local industriel. commercial ou assimilé'}, None, False)\n",
    "formatted_values = ', '.join(filtered_apartments.type_local.unique())\n",
    "print(f\"Les types de biens inclus dans ce jeu de données sont de types : {formatted_values}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Analyses Descriptive\n",
    "        Maintenant nous allons analyser les données historiques pour les 2 différents types de biens immobiliers en essayant d'identifier les relations entre les variables.\n",
    "### 1. Analyse Exploratoire\n",
    "#### 1.1. L'évolution de la moyenne par année de la valeur foncière, du prix au mètre carré, et de la surface, de chaque type de bien :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une figure avec 3 subplots\n",
    "fig = make_subplots(rows=3, cols=1, subplot_titles=('La valeur foncière', 'Le prix au m²', 'La surface'), vertical_spacing=0.1)\n",
    "\n",
    "# Liste des colonnes à tracer\n",
    "columns = ['valeur_fonciere', 'prix_m2', 'surface_reelle']\n",
    "titles_y = ['Valeur foncière (en millions d\\'euros)', 'Metre carré des biens', 'Surface moyenne des biens']\n",
    "\n",
    "# Pour chaque colonne\n",
    "for i, column in enumerate(columns):\n",
    "    df = pd.DataFrame()\n",
    "    # Pour chaque type de local\n",
    "    for type_local in filtered_apartments_and_commercial['type_local'].unique():\n",
    "        # Filtrer le DataFrame par type de local\n",
    "        filtered_df = request_analyze_graph(filtered_apartments_and_commercial, None, {'type_local': type_local}, [column], True)\n",
    "        temp_df = pd.DataFrame(filtered_df[column])\n",
    "        temp_df['type_local'] = type_local\n",
    "        df = pd.concat([df, temp_df])\n",
    "\n",
    "    for type_local in df['type_local'].unique():\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df[df['type_local'] == type_local].index, y=df[df['type_local'] == type_local][column], mode='lines', name=f'{type_local} {column}'),\n",
    "            row=i+1,\n",
    "            col=1\n",
    "        )\n",
    "\n",
    "    fig.update_yaxes(title_text=titles_y[i], row=i+1, col=1)\n",
    "\n",
    "# Mettre à jour les axes et le titre\n",
    "fig.update_layout(title_text=\"Evolution de la moyenne par année selon le type de bien de :\", height=1200, width=1300)\n",
    "fig.update_xaxes(title_text='Années de vente des biens', tickvals=filtered_apartments_and_commercial.index)\n",
    "\n",
    "# Afficher le graphique\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Nous pouvons determiner que la valeur foncière des locaux commerciaux, est 2.5x plus élevé que celle des appartements.  \n",
    "        Et cela peut s'expliquer, non seulement via un prix au mètre carré 1.5x plus élevé ;\n",
    "        Et aussi via une surface 2x plus élevée.\n",
    "\n",
    "        Cependant, nous pouvons noter qu'en 2019, au sujet de la surface, les locaux commerciaux étaient en décroissance sur l'année 2018-2019 ;\n",
    "        Néanmoins, la croissance est bien plus importante au sujet du prix au mètre carré entre l'année 2017 et 2019 ;\n",
    "        Enfin, à partir du courant de l'année 2019, la surface s'accroit de nouveau.\n",
    "        Du fait d'une infime croissance du prix au mètre carré, la valeur foncière du bien s'offre une croissance absolument non négligeable.\n",
    "\n",
    "        En contrepartie, du coté des appartements, la surface des biens proposés décroissait très légèrement jusqu'à commencer à remonter à partir de 2020 ;\n",
    "        Le prix au mètre carré avait suivi proportionnellement la même progression que les locaux, jusqu'à décroitre à partir de 2020 assez fortement ;\n",
    "        Cela représente logiquement la diminution infime que subit la valeur foncière des appartements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Analyse graphique de l'évolution moyenne des appartements par année incluant les différents arrondissement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe contenant la liste des codes postaux :\n",
    "filtered_all_cp = request_analyze_graph(histo_m2, 'historique prix au m2', None, {'code_postal'}, False)\n",
    "\n",
    "# Créer une figure avec 2 subplots pour les appartements\n",
    "fig1 = make_subplots(rows=3, cols=1, subplot_titles=('Valeur foncière', ' prix au m²', 'surface'), vertical_spacing=0.06)\n",
    "\n",
    "# Liste des colonnes à tracer\n",
    "columns = ['valeur_fonciere', 'prix_m2', 'surface_reelle']\n",
    "titles_y = ['Valeur foncière', 'Metre carré des appartements', 'surface en mètre carré']\n",
    "\n",
    "# Pour chaque colonne\n",
    "for i, column in enumerate(columns):\n",
    "    df = pd.DataFrame()\n",
    "    # Pour chaque code postal, triés dans l'ordre alphanumérique\n",
    "    for code_postal in sorted(filtered_all_cp['code_postal'].unique()):\n",
    "        # Filtrer le DataFrame par code postal et type de local\n",
    "        mean_data_by_arrondissement = request_analyze_graph(filtered_apartments[filtered_apartments['type_local'] == 'Appartement'], None, {'code_postal': code_postal}, [column])\n",
    "        \n",
    "        temp_df = pd.DataFrame(mean_data_by_arrondissement)\n",
    "        temp_df['code_postal'] = code_postal\n",
    "        df = pd.concat([df, temp_df])\n",
    "\n",
    "    for code_postal in sorted(df['code_postal'].unique()):\n",
    "        fig1.add_trace(\n",
    "            go.Scatter(x=df[df['code_postal'] == code_postal].index, y=df[df['code_postal'] == code_postal][column], mode='lines', name=f'{code_postal} {column}'),\n",
    "            row=i+1,\n",
    "            col=1\n",
    "        )\n",
    "\n",
    "    fig1.update_yaxes(title_text=titles_y[i], row=i+1, col=1)\n",
    "\n",
    "# Mettre à jour les axes et le titre pour les appartements\n",
    "fig1.update_layout(title_text=\"Evolution de la moyenne des appartements dans chaque arrondissement par année :\", height=1500, width=1300)\n",
    "fig1.update_xaxes(title_text='Années de vente des appartements', tickvals=filtered_apartments_and_commercial.index)\n",
    "\n",
    "# Afficher le graphique pour les appartements\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Nous pouvons remarquer que les 75006, 75007, 75008 et 75016 sont les arrondissements aux valeurs les plus élevées ;\n",
    "        Chacun de ces arrondissements suivent une progression, croissante durant les 2 premières années pour les 75006, 75008, et 75016, et décroissante pour le 75007 ;\n",
    "\n",
    "        Le pic le plus élevé en 2019 est détenu par le 75008 ;\n",
    "        Alors même que le prix au mètre carré du 75008 se situe dans la moyenne haute parmi les différents arrondissement ;\n",
    "        Néanmois, il a pu profiter jusqu'en 2019, des appartements aux plus grandes surfaces, en concurrence avec le 75016 ;\n",
    "        A partir du courant 2019, une decroissance s'effectue, le plaçant second dans l'offre d'appartements aux plus grandes surfaces ;\n",
    "\n",
    "        A partir de courant 2020, le prix au mètre carré des appartements du 75006 est strictement supérieur aux autre arrondissements, tout en restant stable.\n",
    "        Contrairement au 75008, il semble que dans le cas du 75006, la variable prix au mètre carré est donc assujeti à un ou des facteurs semblant l'impacter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Analyse graphique de l'évolution moyenne des locaux par année incluant les différents arrondissement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une figure avec 3 subplots pour les locaux commerciaux\n",
    "fig2 = make_subplots(rows=3, cols=1, subplot_titles=('Valeur foncière', ' prix au m²', 'surface'), vertical_spacing=0.06)\n",
    "\n",
    "# Liste des colonnes à tracer\n",
    "columns = ['valeur_fonciere', 'prix_m2', 'surface_reelle']\n",
    "titles_y = ['Valeur foncière (en millions d\\'euros)', 'Metre carré des locaux commerciaux', 'surface en mètre carré']\n",
    "\n",
    "# Pour chaque colonne\n",
    "for i, column in enumerate(columns):\n",
    "    df = pd.DataFrame()\n",
    "    # Pour chaque code postal, triés dans l'ordre alphanumérique\n",
    "    for code_postal in sorted(filtered_all_cp['code_postal'].unique()):\n",
    "        # Filtrer le DataFrame par code postal et type de local\n",
    "        mean_data_by_arrondissement = request_analyze_graph(filtered_corpo[filtered_corpo['type_local'] == 'Local industriel. commercial ou assimilé'], None, {'code_postal': code_postal}, [column])\n",
    "        \n",
    "        temp_df = pd.DataFrame(mean_data_by_arrondissement)\n",
    "        temp_df['code_postal'] = code_postal\n",
    "        df = pd.concat([df, temp_df])\n",
    "\n",
    "    for code_postal in sorted(df['code_postal'].unique()):\n",
    "        fig2.add_trace(\n",
    "            go.Scatter(x=df[df['code_postal'] == code_postal].index, y=df[df['code_postal'] == code_postal][column], mode='lines', name=f'{code_postal} {column}'),\n",
    "            row=i+1,\n",
    "            col=1\n",
    "        )\n",
    "\n",
    "    fig2.update_yaxes(title_text=titles_y[i], row=i+1, col=1)\n",
    "\n",
    "# Mettre à jour les axes et le titre pour les locaux commerciaux\n",
    "fig2.update_layout(title_text=\"Evolution de la moyenne des locaux commerciaux dans chaque arrondissement par année :\", height=1500, width=1300)\n",
    "fig2.update_xaxes(title_text='Années de vente des locaux commerciaux', tickvals=filtered_apartments_and_commercial.index)\n",
    "\n",
    "# Afficher le graphique pour les locaux commerciaux\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Il semblerait, que le prix au mètre carré des locaux commerciaux pour chacun des arrondissement, suive la même tendence d'évolution que pour les appartements ;\n",
    "        Seulement, les surfaces proposées sont majoritairement plus élevées ;\n",
    "        Il semblerait, que les surfaces les plus petites, des locaux commerciaux, sont aussi grands que la moyenne des surfaces des appartements ;\n",
    "\n",
    "        De part une tendance semblant identique entre locaux commerciaux, et appartement, du prix au mètre carré ;\n",
    "        Tout en étant d'un prix supérieur ;\n",
    "        Couplé à une surface accrue majoritairement ;\n",
    "        Cela donne donc une valeur foncière moyenne d'un ordre de grandeur supérieur ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analyse Multivariée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_histo = request_analyze_graph(histo_m2, 'historique prix au m2', None, ['valeur_fonciere', 'surface_reelle', 'prix_m2', 'year_mutation', 'ordinal_mutation', 'code_postal', 'type_local'], False)\n",
    "corr_histo_flat = request_analyze_graph(histo_m2, 'historique prix au m2', {'type_local': 'Appartement'}, ['valeur_fonciere', 'surface_reelle', 'prix_m2', 'year_mutation', 'ordinal_mutation', 'code_postal', 'type_local'], False)\n",
    "corr_histo_corpo = request_analyze_graph(histo_m2, 'historique prix au m2', {'type_local': 'Local industriel. commercial ou assimilé'}, ['valeur_fonciere', 'surface_reelle', 'prix_m2', 'year_mutation', 'ordinal_mutation', 'code_postal', 'type_local'], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Analyse via la description\n",
    "##### 2.1. Affichage des caractéristiques quantitative des appartements :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_selected_stats(df, columns):\n",
    "    stats = df.describe()[columns]\n",
    "    filtered_stats = stats.loc[['mean', 'min', '50%', 'max']]\n",
    "    return filtered_stats\n",
    "\n",
    "print(f\"Le prix total des ventes d'appartements de l'historique est de {corr_histo_flat['valeur_fonciere'].sum():.2f}€\")\n",
    "print(f\"Parmi les {len(corr_histo.year_mutation)} transactions total, nous avons {len(corr_histo_flat.index)} transactions d'appartements, soit {len(corr_histo_flat.index) / len(corr_histo.year_mutation) * 100:.2f}% des transactions.\")\n",
    "describe_selected_stats(corr_histo_flat, ['surface_reelle', 'prix_m2', 'valeur_fonciere', 'year_mutation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2. Affichage des caractéristiques quantitative des locaux commerciaux :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Le prix total des ventes de locaux commerciaux de l'historique est de {corr_histo_corpo['valeur_fonciere'].sum():.2f}€\")\n",
    "print(f\"Parmi les {len(corr_histo.year_mutation)} transactions total, nous avons {len(corr_histo_corpo.index)} transactions d'appartements, soit {len(corr_histo_corpo.index) / len(corr_histo.year_mutation) * 100:.2f}% des transactions.\")\n",
    "describe_selected_stats(corr_histo_corpo, ['surface_reelle', 'prix_m2', 'valeur_fonciere', 'year_mutation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2. Affichage des caractéristiques quantitative des biens :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Le prix total des ventes de biens de l'historique est de {corr_histo['valeur_fonciere'].sum():.2f}€\")\n",
    "print(f\"Les {len(corr_histo.index)} biens, représentent les {len(corr_histo.index) / len(corr_histo.year_mutation) * 100:.2f}% des transactions.\")\n",
    "describe_selected_stats(corr_histo, ['surface_reelle', 'prix_m2', 'valeur_fonciere', 'year_mutation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"La participation des locaux commerciaux sur le total des ventes en pourcentage s'élève à {(corr_histo_corpo['valeur_fonciere'].sum() / corr_histo['valeur_fonciere'].sum())*100:.2f}%, celle des appartements est donc de {(corr_histo_flat['valeur_fonciere'].sum() / corr_histo['valeur_fonciere'].sum())*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Analyses basée sur les variables qualitatives \"Code Postal\", et \"Date de transaction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Liste des codes postaux dans nos données : {list(filtered_all_cp.code_postal.sort_values().unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analyse du facteur offre face à la demande du 75006 pour les appartements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe contenant l'historique de transaction des appartements dans le 6e arrondissement :\n",
    "filtered_apartment_date06 = request_analyze_graph(corr_histo_flat, 'historique appartements', {'code_postal': 75006}, {'surface_reelle', 'prix_m2', 'valeur_fonciere', 'year_mutation', 'type_local'}, False)\n",
    "\n",
    "print(f\"Parmi les {len(filtered_apartments.index)} transactions total, nous avons {len(filtered_apartment_date06.index)} transactions dans le 6ème arrondissement, soit {len(filtered_apartment_date06.index) / len(filtered_apartments.index) * 100:.2f}% des transactions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Précédente analyse pour les biens corporates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe contenant l'historique de transaction des appartements dans le 6e arrondissement :\n",
    "filtered_corpo_date06 = request_analyze_graph(corr_histo_corpo, 'historique appartements', {'code_postal': 75006}, {'surface_reelle', 'prix_m2', 'valeur_fonciere', 'year_mutation', 'type_local'}, False)\n",
    "\n",
    "print(f\"Parmi les {len(filtered_corpo.index)} transactions total, nous avons {len(filtered_corpo_date06.index)} transactions dans le 6ème arrondissement, soit {len(filtered_corpo_date06.index) / len(filtered_corpo.index) * 100:.2f}% des transactions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Précédente analyse pour tous les biens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe contenant l'historique de transaction des appartements dans le 6e arrondissement :\n",
    "filtered_date06 = request_analyze_graph(corr_histo, 'historique appartements', {'code_postal': 75006}, {'surface_reelle', 'prix_m2', 'valeur_fonciere', 'year_mutation', 'type_local'}, False)\n",
    "\n",
    "print(f\"Parmi les {len(corr_histo.index)} transactions total, nous avons {len(filtered_date06.index)} transactions dans le 6ème arrondissement, soit {len(filtered_date06.index) / len(corr_histo.index) * 100:.2f}% des transactions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Ne connaissant pas la disponibilité des appartements du 75006, je ne peux que continuer sur ma supposition ;\n",
    "        2.91% des appartements représentent une part extrêmement faible, sur un total de 20 arrondissement.\n",
    "        Si cela est dû à une offre restreinte, alors la demande peut facilement devenir élevée, et donc voir ses prix au mètre carré plus élevé.\n",
    "\n",
    "        Cependant, ce prix élevé pourrait être dû à des seuils impactant à tort, la moyenne ;\n",
    "        Dans le cas de moins de 1000 appartements, sur un total de 24.338, l'impact serait non négligeable.\n",
    "\n",
    "        On peut d'ailleurs se servir des appartements du 75007, dont le prix au mètre carré, la surface et la valeur foncière est similaire au 75006. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Analyse comparatif des statistiques descriptives du 75006 face au 75007 pour les appartements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_selected_stats2(df, columns):\n",
    "    stats = df.describe()[columns]\n",
    "    filtered_stats = stats.loc[['mean', 'min', '25%', '50%', '75%', 'max']]\n",
    "    return filtered_stats\n",
    "\n",
    "# Dataframe contenant l'historique de transaction des appartements dans le 6e arrondissement :\n",
    "filtered_apartment_date07 = request_analyze_graph(corr_histo_flat, 'historique appartements', {'code_postal': 75007}, {'surface_reelle', 'prix_m2', 'valeur_fonciere', 'year_mutation', 'type_local'}, False)\n",
    "\n",
    "print(f\"Parmi les {len(filtered_apartments.index)} transactions total, nous avons {len(filtered_apartment_date07.index)} transactions dans le 7ème arrondissement, soit {len(filtered_apartment_date07.index) / len(filtered_apartments.index) * 100:.2f}% des transactions.\")\n",
    "\n",
    "print(\"Describe 75006 :\")\n",
    "display(describe_selected_stats2(filtered_apartment_date06, ['surface_reelle', 'prix_m2', 'valeur_fonciere']))\n",
    "print(\"Describe 75007 :\")\n",
    "display(describe_selected_stats2(filtered_apartment_date07, ['surface_reelle', 'prix_m2', 'valeur_fonciere']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Analyse comparatif des statistiques descriptives du 75006 face au 75007 pour les biens corporates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_selected_stats2(df, columns):\n",
    "    stats = df.describe()[columns]\n",
    "    filtered_stats = stats.loc[['mean', 'min', '25%', '50%', '75%', 'max']]\n",
    "    return filtered_stats\n",
    "\n",
    "# Dataframe contenant l'historique de transaction des appartements dans le 6e arrondissement :\n",
    "filtered_corpo_date07 = request_analyze_graph(corr_histo_corpo, 'historique appartements', {'code_postal': 75007}, {'surface_reelle', 'prix_m2', 'valeur_fonciere', 'year_mutation', 'type_local'}, False)\n",
    "\n",
    "print(f\"Parmi les {len(filtered_corpo.index)} transactions total, nous avons {len(filtered_corpo_date07.index)} transactions dans le 7ème arrondissement, soit {len(filtered_corpo_date07.index) / len(filtered_corpo.index) * 100:.2f}% des transactions.\")\n",
    "\n",
    "print(\"Describe 75006 :\")\n",
    "display(describe_selected_stats2(filtered_corpo_date06, ['surface_reelle', 'prix_m2', 'valeur_fonciere']))\n",
    "print(\"Describe 75007 :\")\n",
    "display(describe_selected_stats2(filtered_corpo_date07, ['surface_reelle', 'prix_m2', 'valeur_fonciere']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5. Analyse comparatif des statistiques descriptives du 75006 face au 75007 pour tous biens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_selected_stats2(df, columns):\n",
    "    stats = df.describe()[columns]\n",
    "    filtered_stats = stats.loc[['mean', 'min', '25%', '50%', '75%', 'max']]\n",
    "    return filtered_stats\n",
    "\n",
    "# Dataframe contenant l'historique de transaction des appartements dans le 6e arrondissement :\n",
    "filtered_date07 = request_analyze_graph(corr_histo, 'historique appartements', {'code_postal': 75007}, {'surface_reelle', 'prix_m2', 'valeur_fonciere', 'year_mutation', 'type_local'}, False)\n",
    "\n",
    "print(f\"Parmi les {len(corr_histo.index)} transactions total, nous avons {len(filtered_date07.index)} transactions dans le 7ème arrondissement, soit {len(filtered_date07.index) / len(corr_histo.index) * 100:.2f}% des transactions.\")\n",
    "\n",
    "print(\"Describe 75006 :\")\n",
    "display(describe_selected_stats2(filtered_date06, ['surface_reelle', 'prix_m2', 'valeur_fonciere']))\n",
    "print(\"Describe 75007 :\")\n",
    "display(describe_selected_stats2(filtered_date07, ['surface_reelle', 'prix_m2', 'valeur_fonciere']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Le nombre de ventes de biens du 75007 est significativement similaire à celui du 75006 ;\n",
    "        Il se trouve que non seulement, les prix min et max du 75006 sont respectivement de 800€ et 700€ environ le mètre carré plus élevés ;\n",
    "\n",
    "        Ceci permet de confirmer à minima, que dans l'évaluation d'une moyenne, son nombre restreint de transactions induit des extrêmes agissant bien plus facilement.\n",
    "        Cependant, la médiane de chaque bien, selon l'arrondissement, bien moins assujetie que la moyenne, par les extrêmes voit sa différence à près de 400€ ;\n",
    "\n",
    "        De ce fait, le prix des appartements comme des locaux dans le 75006, n'est pas anormalement élevé, donc la première hypothèse (l'offre face à la demande), n'est surtout pas à exclure, mais reste impossible à vérifier ;\n",
    "        Nous avons exclusivement l'historique de vente, mais pas le catalogue de vente, si possible, incluant l'historique de vente.\n",
    "\n",
    "        Néanmoins, ses extrêmes bas et haut sont plus élevés que la moyenne des extrêmes des autres arrondissements, agissant donc sur sa propre moyenne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Analyse Inférentielle\n",
    "### 1. Identification des variables à correler\n",
    "        Prix au mètre carré (Variable quantitative) ;\n",
    "        Valeur foncière (Variable quantitative) ;\n",
    "        Surface (Variable quantitative) ;\n",
    "        Types de bien (Variable qualitative) ;\n",
    "        Code postal (Variable qualitative) ;\n",
    "        Date de transaction (Variable temporelle).\n",
    "### 1.1 Choix des méthodes de calcul et d'analyse de corrélation\n",
    "        L'objectif étant de pouvoir comparer les deux secteurs (Appartements et Locaux commerciaux), provenant d'un jeu de données dans lequel nous devrons effectuer une prédiction, cela signifie que :\n",
    "          Nous devons prédire la valeur foncière\n",
    "        Donc nous allons déterminer le choix des méthodes, afin de non seulement conserver, mais aussi verifier, les variables l'influençant :\n",
    "          La méthode de Pearson, utilisée dans la méthode corr de Pandas, elle calcule le coefficient de correlation interquantitative ;\n",
    "          La méthode de Spearman, Permet de comparer une variable temporelle, et une variable quantitative ;\n",
    "          L'analyse bivariée, ANOVA, analyse la relation entre une variable qualitattive, et quantitative ;\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mettre à jour les listes de colonnes\n",
    "quant_cols = ['prix_m2', 'valeur_fonciere', 'surface_reelle', 'ordinal_mutation']\n",
    "qual_cols = ['code_type_local', 'code_postal']\n",
    "temporal_cols = ['year_mutation']\n",
    "\n",
    "name_mapping = {\n",
    "    'prix_m2': 'Prix au mètre carré',\n",
    "    'valeur_fonciere': 'Valeur foncière',\n",
    "    'surface_reelle': 'Surface réelle',\n",
    "    'code_type_local': 'Type de bien',\n",
    "    'code_postal': 'Code postal',\n",
    "    'ordinal_mutation': 'Année de transaction ordinale',\n",
    "    'year_mutation': 'Année de transaction annuelle'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. La corrélation linéaire quantitative de Pearson\n",
    "        Cette méthode représente le calcul de corrélation par défaut, pour toute variable quantitative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Expression simplifiée mathématique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les symboles\n",
    "x, y, x_bar, y_bar, n = smp.symbols('x y x_bar y_bar n')\n",
    "# Formule du coefficient de corrélation de Pearson\n",
    "pearson = smp.Sum((x - x_bar)*(y - y_bar), (x, 1, n)) / smp.sqrt(smp.Sum((x - x_bar)**2, (x, 1, n)) * smp.Sum((y - y_bar)**2, (y, 1, n)))\n",
    "\n",
    "display(pearson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Cette équation donne en résultat r, étant le coefficient.\n",
    "        x et y étant les variables ;\n",
    "        i devant suivre ces variables, afin de déterminer les valeurs individuelles ;\n",
    "        xbar et ybar étant les moyennes de x et y ;\n",
    "        Sigma étant la somme de l'addition pour toutes les valeurs de i.\n",
    "        n étant le nombre total d'observations, en l'occurrence 26180."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2. Calcul de correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créez un DataFrame pour stocker les résultats\n",
    "pearson_corr = pd.DataFrame(columns=['Variables influençables', 'Coefficient de corrélation avec la valeur foncière', 'Probabilité'])\n",
    "\n",
    "for i, col in enumerate(quant_cols):\n",
    "    if col != 'valeur_fonciere':  # Évitez de corréler la variable avec elle-même\n",
    "        corr, p_value = pearsonr(histo_m2['valeur_fonciere'], histo_m2[col])\n",
    "        pearson_corr.loc[i] = [name_mapping[col], corr, p_value]  # Ajoutez une nouvelle ligne avec loc\n",
    "\n",
    "display(pearson_corr.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Il y a une faible corrélation positive entre le prix au mètre carré et la valeur foncière.\n",
    "            La valeur p est inférieure à 0,05, ce qui signifie que cette corrélation est statistiquement significative.\n",
    "        Il y a une très faible corrélation positive entre le prix au mètre carré et la surface réelle.\n",
    "            Cette corrélation est également statistiquement significative.\n",
    "        Il y a une très forte corrélation positive entre la valeur foncière et la surface réelle, ce qui est statistiquement significatif.\n",
    "\n",
    "        En comparant avec l'année de transaction ordinale, nous pouvons remarquer une faible corrélation, similaire à celle des deux premières correlations ;\n",
    "            Cependant, comparée à la surface réelle, la p-value étant significativement élevée, le coefficient du calcul ne semble pas être fondé.\n",
    "        \n",
    "        Pour conclure, la surface réelle semble véritablement être une influence sur la valeur d'un bien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. La corrélation non linéaire via la méthode de Spearman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        La méthode de Spearman s'appuie sur ce que l'on nomme les rangs de valeurs ;\n",
    "        Son objectif est de mesurer la relation entre plusieurs variables dont leur croissance sont monotones.\n",
    "\n",
    "        Dans le cas d'une monotonie décroissante, lorsque une variable augmente, l'autre diminue ;\n",
    "        Dans le cas contraire, les deux variables augmentent.\n",
    "\n",
    "        Cependant, le rythme d'évolution des dites variables, n'est pas nécessairement équivalente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1. Calcul de correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Créez un DataFrame pour stocker les résultats\n",
    "spearman_corr = pd.DataFrame(columns=['Variable influençable', 'Corrélation de Spearman avec Valeur foncière', 'Probabilité'])\n",
    "\n",
    "corr, p_value = spearmanr(histo_m2['valeur_fonciere'], histo_m2['ordinal_mutation'])\n",
    "spearman_corr.loc[0] = ['Année de transaction ordinale', corr, p_value]\n",
    "\n",
    "display(spearman_corr.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. La corrélation via l'analyse de la variance d'ANOVA\n",
    "        Cette analyse permet d'étudier les moyennes des variables quantitatives, dans chaque groupes appartenant aux différentes variables qualitatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1. Expression simplifiée mathématique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les symboles\n",
    "mu, alpha_i, epsilon_ij = smp.symbols('mu alpha_i epsilon_ij')\n",
    "# Formule de l'ANOVA\n",
    "Y_ij = mu + alpha_i + epsilon_ij\n",
    "\n",
    "display(Y_ij)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2. Analyse de la variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créez un DataFrame pour stocker les résultats\n",
    "anova_results = pd.DataFrame(columns=['Variables', 'Sum-Squared', 'degrees Freedom', 'Mean-Squared', 'F Statistic', 'PR[>F]'])\n",
    "\n",
    "for i, qual_col in enumerate(qual_cols):\n",
    "    model = ols('valeur_fonciere ~ C({})'.format(qual_col), data=histo_m2).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    ss = anova_table.loc['C({})'.format(qual_col), 'sum_sq']\n",
    "    df = anova_table.loc['C({})'.format(qual_col), 'df']\n",
    "    ms = ss / df  # Calculez la moyenne des carrés\n",
    "    f_value = anova_table.loc['C({})'.format(qual_col), 'F']\n",
    "    p_value = anova_table.loc['C({})'.format(qual_col), 'PR(>F)']\n",
    "    anova_results.loc[i] = [name_mapping[qual_col], ss, df, ms, f_value, p_value]\n",
    "\n",
    "display(anova_results.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Matrices de corrélation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(quant_cols)\n",
    "display(qual_cols)\n",
    "display(temporal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer la matrice de corrélation\n",
    "corr_matrix = histo_m2[quant_cols + qual_cols + temporal_cols].corr()\n",
    "# Créer un graphe à partir de la matrice de corrélation\n",
    "G = nx.Graph()\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):  # On ne considère que la moitié supérieure de la matrice\n",
    "        # Ajouter une arête entre chaque paire de variables, pondérée par leur corrélation\n",
    "        G.add_edge(corr_matrix.columns[i], corr_matrix.columns[j], weight=abs(corr_matrix.iloc[i, j]))\n",
    "# Créer une figure avec une largeur spécifique\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Dessiner le graphe avec une disposition circulaire pour une meilleure visibilité\n",
    "pos = nx.circular_layout(G)\n",
    "edges = G.edges()\n",
    "weights = [G[u][v]['weight']*5 for u,v in edges]  # Multiplier les poids par 5 pour les rendre plus visibles\n",
    "nx.draw(G, pos, with_labels=True, width=weights)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Conclusion :\n",
    "        Les différentes variables qualitatives que sont le type_local, et le code_postal, sont pertinentes afin de trouver la valeur foncière ;\n",
    "        De même pour la variable temporelle, comme quantitative discrète, year_mutation, et ordinal_mutation ;\n",
    "        Enfin, la variable quantitative surface_réelle serait la clé permettant de déployer l'intêret des variables autres.\n",
    "        Nous excluons du jeu de donnée le prix au mètre carré, étant le résultat de la valeur foncière divisée par la surface, cela fausserait la prédiction.\n",
    "\n",
    "        Nous pouvons donc nous atteler à la phase de l'analyse prédictive dans le chapitre suivant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Analyse prédictive\n",
    "        Dans cette section nous allons maintenant entraîner un algorithme à prédire la valeur foncière d'un bien immobilier.  \n",
    "        Pour cela nous allons utiliser l'algorithme de régression linéaire.  \n",
    "        On commence par préparer nos données en transformant les colonnes catégoriques du code postal et du type de local grâce au one hot encoder (sklearn) / get_dummies (pandas).\n",
    "### 1. Dataset :\n",
    "#### 1.1. Préprocessus des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['ordinal_mutation', 'year_mutation', 'code_postal', 'code_type_local', 'surface_reelle', 'valeur_fonciere']\n",
    "dummies = ['code_postal', 'code_type_local']\n",
    "histo_train = prepare_df_model(histo_m2, 'histo_train', data, dummies)\n",
    "analyze_dataframe(histo_train, 'histo_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Création des variables d'entrainements et de la cible :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = histo_train.drop(['valeur_fonciere'], axis=1)\n",
    "y = histo_train['valeur_fonciere']\n",
    "get_table_info(histo_train, 'Jeu de donnée prévu pour l\\'entraînement')\n",
    "get_table_info(X, 'Jeu de donnée d\\'entraînement')\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Mise à l'échelle des variables d'entraînements :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Fonction aggrégatrice fit et predict models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(X_scaled, y, test_size=0.33, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modèles :\n",
    "        Nous allons maintenant mettre en place différents modèles algorithmiques, dans le but de tirer la meilleure prédiction possible.  \n",
    "        Nous avons un jeu de donnée de 24 colonnes contenant chacune, 26196 valeurs ; Nous avons donc un jeu de donnée surpassant largement les 100 000 valeurs !  \n",
    "        De plus, nous comptons prédire, des valeurs quantitatives !  \n",
    "        De ce fait, nous pouvons donc utiliser des algorithmes prévus pour les gros jeux, afin d'éviter ce que l'on nomme l'over, et l'under, fitting.  \n",
    "        Néanmoins, la cible étant quantitative, nous parlons donc d'un problème de régression :  \n",
    "<img src=\"https://scikit-learn.org/stable/_static/ml_map.png\" alt=\"Machine Learning Mind Map provenant du site Sci-Kit Learn\" width=\"900\"/>  \n",
    "\n",
    "        Voici donc une liste des algorithmes et selon ce que ce dernier offre, des méthodes, que nous allons tester, comparer.  \n",
    "        Nous pourrons donc retenir celui affectant le moins d'erreur moyenne en pourcentage :  \n",
    "        LLS (Linear Least Squared - La méthode des moindres carrés):\n",
    "            Régression Linéaire ordinaire (OLS) ;  \n",
    "            LASSO ;  \n",
    "            Ridge ;  \n",
    "            Scholastic Gradient Descent (SGDR) ;  \n",
    "        Les méthodes Lasso et Ridge, fonctionnent différemment de la méthode ordinaire. La différence se trouve via l'argument alpha, couplé aux nombres d'itérations maximum.  \n",
    "        Cela revient au même que la méthode Gradient Descent, mettre en place un algorithme de minimisation, qui se base sur la fonction coût.  \n",
    "        L'alpha représente un pas d'apprentissage, dont son but, via un nombre d'itérations donné, de minimiser la fonction coût, c'est à dire de minimiser l'erreur.  \n",
    "            KNN (K-Near Neighbors) ;  \n",
    "            NLR (Non-Linear Regression - Régression non linéaire) :  \n",
    "                Random Forest;  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lR(fit_intercept=True, copy_X=True, n_jobs=None), #Régression linéaire - OLS\n",
    "        l1(max_iter=100000, fit_intercept=True, copy_X=True, random_state=0), #Régression linéaire - Lasso\n",
    "        l2(max_iter=100000, fit_intercept=True, copy_X=True, random_state=0), #Régression linéaire - Ridge\n",
    "        sgdR(alpha=0.064, loss='squared_error', penalty='elasticnet', fit_intercept=True,\n",
    "            learning_rate='constant', early_stopping=False, validation_fraction=0.1,\n",
    "            n_iter_no_change=5, warm_start=False, average=False, random_state=5), #Régression linéaire - Stochastic Gradient Descent\n",
    "        rfR(max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "            n_jobs=12, random_state=0,warm_start=False,\n",
    "            ccp_alpha=0.0,max_samples=None,n_estimators=100), #Forêt d'arbres aléatoire\n",
    "        knnR(algorithm='auto', leaf_size=30,\n",
    "            metric='minkowski',metric_params=None,n_jobs=4,p=2,\n",
    "            weights='uniform'),#K-Near Neighbors\n",
    "        ]\n",
    "model_names = ['linearR','lasso', 'ridge', 'sgdR', 'randomfR', 'knearnR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Résultats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, trained_models, y_preds = train_and_evaluate_models(models, model_names, X_train, y_train, X_test, y_test, [1, 3, 5], [1, 10])\n",
    "\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {len(value)}\")\n",
    "best_model, comparison_df = create_comparison_table(results)\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Création d'une nouvelle table pour stocker les données y_preds et y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Représentation graphique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['valeurs_réelles'] = y_test\n",
    "\n",
    "# Ajout des données y_preds à la table data\n",
    "model_names = list(y_preds.keys())\n",
    "for model_name in model_names:\n",
    "    for j in range(len(y_preds[model_name])):\n",
    "        column_name = model_name\n",
    "        if model_name == 'knearnR':\n",
    "            hyperparam_name = 'n_neighbors'\n",
    "            hyperparam_value = results[hyperparam_name][j]\n",
    "            column_name = f\"{model_name}_{hyperparam_value}\"\n",
    "        elif model_name == 'lasso' or model_name == 'ridge':\n",
    "            hyperparam_name = 'alpha'\n",
    "            hyperparam_value = results[hyperparam_name][j]\n",
    "            column_name = f\"{model_name}_{hyperparam_value}\"\n",
    "        column_name = f\"y_pred_{column_name}\"\n",
    "        data[column_name] = y_preds[model_name][j]\n",
    "\n",
    "# Création du graphique\n",
    "fig = px.box(data.melt(var_name='model', value_name='value'), x='value', y='model', orientation='h', points='outliers')\n",
    "fig.update_layout(title='Distribution des valeurs prédites de chaque modèles et des valeurs réelles', xaxis_title='Valeurs foncière', yaxis_title='Modèles')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Notre algorithme fait donc 8.72% d'erreur en moyenne sur la prédiction de la valeur foncière.\n",
    "        Mes conclusions sur ce résultat et comment j'aurais pu aller plus loin :\n",
    "            En ayant une un résultat d'une moyenne d'erreur à 8.72%, je me retrouve avec un pourcentage au-delà de l'acceptable ;\n",
    "            Mais 33% du jeu de données peut ne pas être suffisant, de ce fait, en accédant à 100% du jeu de données, le modèle sera plus entraîné, cependant, nous provoquerions le phénomène d'overfitting (le sur entraînement).\n",
    "            Je pense qu'hormis en modifiant le type d'algorithme, via un modèle non linéaire, tels que l'arbre de décision, une forêt aléatoire ou un réseau de neurones par exemple, mes résultats pourrait croître.\n",
    "\n",
    "        Maintenant que l'entraînement est terminé, nous pouvons donc effectuer la prédiction dans le portefeuille."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Prédiction définitive et analyse préscriptive pour le client\n",
    "        Nous avons récupéré le fichier avec le portefeuille des actifs de la société.  \n",
    "        Nous allons l'importer puis effectuer la prédiction et statuer sur la branche qui, selon notre prédiction, aura le plus de valeur à la date demandée c'est à dire au 31 décembre 2022.  \n",
    "        Petite précision, nous souhaitons continuer à utiliser la surface réelle pour faire les calculs et pas la surface carrez.\n",
    "### 1. Import des données dans un dataframe\n",
    "        Nous avons la liste des biens immobiliers de l'entreprise. Pour effectuer une prédiction, nous devons mettre ce fichier au même format que le dataframe que nous avons utilisé lors de l'entraînement de l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet_prepare = prepare_df_model(wallet_m2, 'wallet_prepare', ['ordinal_mutation','year_mutation', 'code_postal', 'code_type_local', 'surface_reelle'], ['code_postal', 'code_type_local'])\n",
    "\n",
    "get_table_info(X, 'X_train')\n",
    "get_table_info(wallet_prepare, 'Portefeuille préparé à la prédiction')\n",
    "analyze_dataframe(wallet_prepare, 'Portefeuille préparé à la prédiction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Mise à l'échelle des variables d'entraînements :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled2 = scaler.transform(wallet_prepare)\n",
    "display(X_scaled2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Initialisation de la boucle de séléction des modèles de prédiction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for model_name, model in trained_models.items():\n",
    "    y_pred = model.predict(X_scaled2)\n",
    "    data[f'{model_name}_pred'] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. création un dictionnaire contenant les prédictions de chaque modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, y_pred in data.items():\n",
    "    print(f'Nombre de valeurs prédites pour le modèle {model_name}:')\n",
    "    print(len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Ajouter les prédictions de chaque modèle en tant que nouvelles colonnes du DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name, column_data in data.items():\n",
    "    wallet_prepare = wallet_prepare.assign(**{column_name: column_data})\n",
    "\n",
    "# Afficher les premières lignes du DataFrame mis à jour\n",
    "display(wallet_prepare.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fusion des variables \"Type de bien\" et attribution des données \"y\" (0 pour les \"appartements\", et 1 pour les \"local industriel. commercial ou assimilé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_local_columns = ['code_type_local_2', 'code_type_local_4']\n",
    "conditions = [wallet_prepare[col] == 1 for col in type_local_columns]\n",
    "choices = ['Appartement', 'Local industriel. commercial ou assimilé']\n",
    "wallet_prepare['type_local'] = np.select(conditions, choices, default=np.nan)\n",
    "wallet_prepare['type_local'] = wallet_prepare['type_local'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Attribution des données \"y\" dans une nouvelle colonne de type catégorique \"Type de bien\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postal_code_columns = [col for col in wallet_prepare.columns if col.startswith('code_postal_')]\n",
    "conditions = [wallet_prepare[col] == 1 for col in postal_code_columns]\n",
    "choices = [col.split('_')[-1] for col in postal_code_columns]\n",
    "wallet_prepare['code_postal'] = np.select(conditions, choices, default=np.nan)\n",
    "wallet_prepare['code_postal'] = wallet_prepare['code_postal'].astype('category')\n",
    "\n",
    "wallet_prepare = wallet_prepare.drop(columns=type_local_columns + postal_code_columns) # Suppression des colonnes originales booléennes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Affichons donc les infos du nouveau dataframe incluant les prédictions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_table_info(wallet_prepare, 'Portefeuille avec valeur_foncière prédite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Valorisation du portefeuille sur le segment des particuliers\n",
    " Liste des noms des colonnes se terminant par '_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_columns = [col for col in wallet_prepare.columns if col.endswith('_pred')]\n",
    "\n",
    "# Dictionnaires pour stocker les résultats pour chaque colonne\n",
    "total_value = {}\n",
    "count = {}\n",
    "mean_value = {}\n",
    "type_local_choices = ['Appartement', 'Local industriel. commercial ou assimilé']\n",
    "\n",
    "# Parcourir les noms des colonnes se terminant par '_pred'\n",
    "for col in pred_columns:\n",
    "    # Calculer la valeur totale, le compte et la valeur moyenne pour chaque type de propriété\n",
    "    total_value[col] = [wallet_prepare.loc[wallet_prepare['type_local'] == choice][col].sum() for choice in type_local_choices]\n",
    "    count[col] = [wallet_prepare.loc[wallet_prepare['type_local'] == choice].shape[0] for choice in type_local_choices]\n",
    "    mean_value[col] = [wallet_prepare.loc[wallet_prepare['type_local'] == choice][col].mean() for choice in type_local_choices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Affichage des résultats :\n",
    " Créer un DataFrame contenant les valeurs totales prédites pour chaque type de propriété et pour chaque modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_value_df = pd.DataFrame(total_value)\n",
    "total_value_df['Type de bien'] = type_local_choices\n",
    "\n",
    "# Parcourir les noms des modèles\n",
    "for col in pred_columns:\n",
    "    print(f\"Informations pour le modèle {col}\")\n",
    "    # Afficher les informations pour chaque type de propriété\n",
    "    for i, choice in enumerate(type_local_choices):\n",
    "        print(f\"Valorisation prédite pour le segment {choice}, (en millions d'euros) est de : {total_value[col][i] / 1000000}\")\n",
    "        print(f\"Voici le nombre total de {choice} présents : {count[col][i]}\")\n",
    "        print(f\"Voici le prix d'un {choice} selon la valeur foncière prédite : {mean_value[col][i]}\")\n",
    "        print(separe)\n",
    "    print(separe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Affichage via graphique sur la base de la variable qualitative \"Type de bien\", la variable quantitative \"Valeur foncière prédite\" :\n",
    "##### 3.3.1. Analyse de la somme de la variable quantitative :\n",
    " Restructurer le DataFrame pour avoir une forme longue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_value_df = total_value_df.melt(id_vars='Type de bien', var_name='Modèle', value_name='Valeur foncière prédite')\n",
    "\n",
    "# Créer un graphique à barres montrant la valeur totale prédite pour chaque type de propriété et pour chaque modèle\n",
    "fig = px.bar(total_value_df, x='Type de bien', y='Valeur foncière prédite', color='Modèle', barmode='group', title='Somme de la valeur de chaque type de bien', height=600, width=1200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous souhaitez garder qu'une seule prédiction parmi la liste des modèles :\n",
    "- linear_pred: Regression Linéaire ;\n",
    "- lasso_pred: Lasso ;\n",
    "- ridge_pred: Ridge ;\n",
    "- sgd_pred: Stochastic Gradient Descent ;\n",
    "- randomf_pred: Random Forest ;\n",
    "- knear_pred: K-Near Neighbors ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.2. Analyse de la moyenne de la variable quantitative :\n",
    " Créer un DataFrame contenant les valeurs moyennes prédites pour chaque type de propriété et pour chaque modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value_df = pd.DataFrame(mean_value)\n",
    "mean_value_df['Type de bien'] = type_local_choices\n",
    "# Restructurer le DataFrame pour avoir une forme longue\n",
    "mean_value_df = mean_value_df.melt(id_vars='Type de bien', var_name='Modèle', value_name='Valeur foncière prédite')\n",
    "# Créer un graphique à barres montrant la valeur moyenne prédite pour chaque type de propriété et pour chaque modèle\n",
    "fig = px.bar(mean_value_df, x='Type de bien', y='Valeur foncière prédite', color='Modèle', barmode='group', title='Prix d\\'un bien de chaque type', height=600, width=1200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mes conclusions sur le segment avec la plus grande valorisation et sur les limites de cette estimation :\n",
    "- Comme attendu, malgré un nombre de locaux corporates en decà des appartements, la valeur reste plus élevée.\n",
    "- Le modèle proposant les prix les plus justes semble être le Random Forest.\n",
    "#### 3.4. Voyons donc la moyenne du prix au mètre carré des différents types de biens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez indiquer en commentaire les autres (via le '#'), et retirer le '#' de l'instruction comportant la prédiction souhaitée :\n",
    "# wallet_prepare['prix_m2'] = wallet_prepare['linearR_pred'] / wallet_prepare['surface_reelle']\n",
    "# wallet_prepare['prix_m2'] = wallet_prepare['lasso_pred'] / wallet_prepare['surface_reelle']\n",
    "# wallet_prepare['prix_m2'] = wallet_prepare['ridge_pred'] / wallet_prepare['surface_reelle']\n",
    "# wallet_prepare['prix_m2'] = wallet_prepare['sgdR_pred'] / wallet_prepare['surface_reelle']\n",
    "# wallet_prepare['prix_m2'] = wallet_prepare['knearnR_pred'] / wallet_prepare['surface_reelle']\n",
    "wallet_prepare['prix_m2'] = wallet_prepare['randomfR_pred'] / wallet_prepare['surface_reelle']\n",
    "display(wallet_prepare.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.1. Préparation de la moyenne du prix au mètre carré :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_price_per_m2 = {}\n",
    "\n",
    "# Parcourir les types de biens\n",
    "for choice in type_local_choices:\n",
    "    # Calculer la moyenne du prix au mètre carré pour chaque type de bien\n",
    "    mean_price_per_m2[choice] = wallet_prepare.loc[wallet_prepare['type_local'] == choice]['prix_m2'].mean()\n",
    "\n",
    "# Créer un DataFrame contenant les résultats\n",
    "mean_price_per_m2_df = pd.DataFrame(mean_price_per_m2, index=['Prix moyen au mètre carré']).T.reset_index()\n",
    "mean_price_per_m2_df.columns = ['Type de bien', 'Prix moyen au mètre carré']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.2. Préparation de la moyenne du prix au mètre carré :\n",
    " Créer un graphique à barres montrant la moyenne du prix au mètre carré pour chaque type de bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(mean_price_per_m2_df, x='Type de bien', y='Prix moyen au mètre carré', title='Prix moyen au mètre carré pour chaque type de bien', height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc si nous comparons les prix moyens au mètre carré pour chaque type de bien, entre ceux du 75006, et ceux de la prédiction :\n",
    "- la différence de prix entre les deux types de biens s'éléve à 14.86 - 13.12, soit 1740 euros de différence ;\n",
    "- Du coté de la prédiction, la différence s'élève à 11.74 - 10.35, soit 1390 euros de différence.  \n",
    "Cela renforce une certaine cohérence dans la différence du prix du mètre carré dans la prédiction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- Classification des données non-supervisé issues du jeu de test\n",
    "Dans cette partie nous allons labelliser automatiquement les biens immobiliers comme étant :\n",
    "- soit des Appartements\n",
    "- soit des Local industriel. commercial ou assimilé\n",
    "### 1. L'algorithme KMeans sur le jeu de données partagé par l'entreprise.\n",
    "Pour que l'algorithme fonctionne, il faut que nous préparions les données.  \n",
    "Nous supprimons les dimensions inutiles et en nous concentrant sur le facteur discriminant entre les appartements et les locaux commerciaux : \n",
    "- la différence dans le prix au mètre carré tel que nous l'avons vu avant.\n",
    "#### 1.1. Création des variables d'entrainements et de la cible :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['valeur_fonciere', 'code_postal', 'nom_commune', 'surface_reelle']\n",
    "merged_df_correspondance = pd.merge(histo_clean, sample, on=cols, how='inner', indicator=True)\n",
    "\n",
    "display(merged_df_correspondance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sample_pred.info())\n",
    "X_cluster = sample_pred[['prix_m2']]\n",
    "display(X.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous observons dans les données que nous avons des valeurs différentes de prix au mètre carré pour un même arrondissement (ici le 19ème arrondissement).  \n",
    "Il se peut fort que cela soit notre dimension à utiliser pour attribuer les prix au mètre carré les plus élévé dans un département aux locaux commerciaux, et les prix les plus bas aux appartements.  \n",
    "Pour effectuer cette opération, nous allons utiliser l'algorithme du Kmeans qui va rechercher 2 centroïdes à travers les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = KMeans(n_clusters=2, n_init=10, random_state=0).fit_predict(X_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons obtenu notre prédiction. Nous pouvons changer les labels et remplacer les valeurs à 0 par Local industriel. commercial ou assimilé et les valeurs à +1 par Appartement.\n",
    "On vérifie les données de la prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.vectorize({0: 'Local industriel. commercial ou assimilé', 1: 'Appartement'}.get)(y_pred)\n",
    "sample_prediction = X_cluster.copy()\n",
    "sample_prediction['type_local'] = y_pred\n",
    "display(sample_prediction.type_local.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Créer le graphique\n",
    "sns.boxplot(data=sample_prediction, x='type_local', y='prix_m2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc les résultats renommés en tant que type de bien. Nous allons donc, en nous aidant de la feuille \"sample_soluce\", créer un tableau croisé dynamique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sample_soluce.head())\n",
    "sample_soluce['cluster'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sample_soluce.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.crosstab(sample_soluce.type_local, sample_soluce.cluster)\n",
    "ct.index.name = 'Cluster'\n",
    "ct.columns.name = 'Type local'\n",
    "display(ct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(ct, color_continuous_scale='Viridis')\n",
    "fig.update_layout(title='Heatmap', height=700, width=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de faire correspondre notre échantillon, avec la feuille de solution, commençons par réintroduire toutes les colonnes prévues au départ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prediction = pd.concat([sample, sample_prediction], axis=1)\n",
    "display(sample_prediction.info())\n",
    "display(sample_soluce.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les résultats sous forme de graphique de la prédiction, et de la solution :\n",
    " Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([sample_prediction.assign(dataset='sample_prediction'), sample_soluce.assign(dataset='sample_soluce')])\n",
    "\n",
    "# Création du graphique\n",
    "fig = px.box(data, x='type_local', y='prix_m2', color='dataset', width=700, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 5 - Analyse et présentation des résultats\n",
    "Mes conclusions sur l'analyse et les limites de l'exercice :\n",
    "- Kmeans -> non supervisé |Algorithmes supervisés préférables\n",
    "- Si une variable semble justifier l'usage de clustering, les données à prédire restent catégorielles ; Cependant Kmeans est approprié pour des données continues.\n",
    "- La différence du prix au mètre carré entre les appartements et les locaux commerciaux est en cohérence aevc les analyses que nous avions fait précédemment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
